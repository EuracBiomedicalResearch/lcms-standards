---
title: "Estimating isotope peak intensities for compounds defined in HMDB"
author: "Andrea Vicini, Johannes Rainer"
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    toc_depth: 3
    fig_width: 5
---

```{r style, echo = FALSE, results = 'asis', message = FALSE}
library(BiocStyle)
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

**Last modified:** `r file.info("isotope-intensity-estimation.Rmd")$mtime`<br />
**Compiled**: `r date()`

# Introduction

In this document we evaluate possibilities to estimate abundances for isotopes
without knowing the chemical formula for the compound. To this end we analyze
the element composition of all compounds in the human metabolome database
([HMDB](https://hmdb.ca)).

The ultimate goal would be to have one or more functions that allow to identify
peaks in (MS1) spectra representing isotopes of the same compound based
exclusively on the m/z and intensity values, i.e. without knowing the chemical
formula of the compound. The functions should be modular and customizable and
should support low as well as high resolution instruments that would allow to
discriminate between isotope peaks from different elements.


# Isotope detection approaches


## `CAMERA`

[`CAMERA`](https://bioconductor.org/packages/release/bioc/html/CAMERA.html)
takes a simple approach based on hard coded lower and upper limits for isotope
peaks. How this limits were defined is unclear. For the m/z differences of the
peaks simple lower and upper limits are used, not discriminating between
e.g. C13 and N15 isotopes.

## `envipat`

[`envipat`](https://cran.r-project.org/web/packages/enviPat/) does not seem to
allow identifying isotopes in MS data but does predict an isotope (intensity)
distribution from a chemical formula.


## Breen et al. 2000. Automatic poisson peak harvesting for high throughput protein identification

The authors consider Poisson modelling of isotopic distributions. Given a 
molecule with mass m they find a mapping F between m and the mean M of the 
Poisson distribution model (F: m-> M).
To compute this mapping they derive from a database a hypothetical average 
aminoacid. Next they use this to construct a set of the theoretical peptides 
whose mass span a certain range of interest. They compute the isotopic 
distribution of those and for each one of them they compute M* as the value of M 
that makes Poisson(M) more similar to the isotopic distribution. Finally they 
fit a line for the values of m against the M* and this line represents the 
mapping F. In the end, they model the isotopic distribution of a compound with 
mass m as a Poisson(P(M))

## Park et al. 2008. Isotopic peak intensity ratio based algorithm for determination of isotopic clusters and monoisotopic masses of polypeptides from high-resolution mass spectrometric data

The following statements are reported for the isotopic distribution of a compound 
with elements C, H, N, O, S.
- the intensity of a peak Ik approximates to a polynomial in m (molecular weight) 
  with degree k
- the ratio between consecutive peaks (R) approximates to a linear function in m
- the ratio product between adjacent peaks (RP) approximates to a constant.

For the last two, the more m is big the better the above approximations get.

To find a relation between R and m they consider a large number of polypeptides 
in a certain database spanning a certain range (400-5200 Da) and for them 
they compute R. Then, the interval of interest is divided in two regions 
(at 1800 Da). For high masses a linear approximation is used and 
its coefficients are found by fitting a regression line whereas for low masses
they use a quotient of polynomials (with degree k+1 and k for the k-th R)

The algorithm to cluster isotopic peaks after peak peaking) involves:

- pseudocluster identification. It requires to loop over all the peaks and for
  each of them find groups of peaks starting with the current peak and separated
  by +1 (in the single charged case) for each peak. They first enumerate
  pseudoclusters with two peaks, then pseudoclusters with more peaks and then
  proceed by considering different charged states.
- isotopic cluster identification. Among the pseudoclusters, they identify
  isotopic clusters whose intensity patterns are similar to those of the
  isotopic distributions in terms of R and RP in the pseudocluster.
- duplicate cluster removal. In case two clusters overlap they remove the one
  whose most abundant peak is smaller. If the most abundant peaks are the same,
  the one with the lowest charge state is removed. If their charge states are
  also the same, the cluster with the lower "similarity score" is removed.

## Valkenborg et al. 2008. A Model-Based Method for the Prediction of the Isotopic Distribution of Peptides

Also in this article the authors consider the ratios between peak heights.
They model it as a polynomial model in m (monoisotopic mass) whose order 
is empirically determined by looking at the improvements obtained by adding 
higher order terms.
The parameters of the polynomial model are estimated using the least-squares 
method on different sets of theoretical peptides (and the model is valid in the 
corresponding mass range).
By comparing the ratios between a series of peaks observed in a spectrum with 
the ratios predicted from the model and selecting a treshold for the allowed 
"difference" they decide whether the series of peaks is part of an isotopic group
or not.

## sgibb

As far as I have understood sgibb uses a mixed approach. He uses the approach of 
Park et al. 2008 but for checking if a candidate cluster is a isotope cluster, 
for which he uses the Poisson approach of Breen et al. 2000.


# Element counts in HMDB

In this section we analyze element compositions of compounds from the Human
Metabolome Database.

```{r libraries, warning = FALSE}
library("CompoundDb")
library("MetaboCoreUtils")
library("pander")
```

We load the HMDB database and extract the chemical formula and exact mass of all
compounds.

```{r}
#cdb <- CompDb("data/CompDb.Hsapiens.HMDB.4.0.sqlite")
cdb <- CompDb("~/CompDb.Hsapiens.HMDB.4.0.sqlite")
cmps <- compounds(cdb, columns = c("compound_id", "name",
                                   "formula", "exactmass"))
```

For each compound in the human metabolom database (HMDB) with available mass 
we compute how many atoms of C, H, N, O, P and S are present in it. 
We collect the counts in a data frame with a column for each element and a row 
for each compound in HMDB.

```{r}
cmps <- cmps[-which(is.na(cmps$exactmass)), ]
```

```{r}
CHNOPS <- c("C", "H", "N", "O", "P", "S", "Cl")
counts <- lapply(cmps$formula, function(frml) {
  res <- countElements(frml)
  row <- data.frame(matrix(0, nrow = 1, ncol = length(CHNOPS)))
  names(row) <- CHNOPS
  only <- intersect(CHNOPS, names(res))
  row[1, only] <- res[only]
  row
  })
counts_df <- do.call(rbind, counts)
rownames(counts_df) <- cmps$compound_id
```

We compute the mean and standard deviation for the number of each element in the
molecules of HMDB. For each element we also report the percentage of compounds 
which have at least one atom of the given element.

```{r, echo = FALSE, results = "asis"}
m_sd <- rbind(colMeans(counts_df), 
              apply(counts_df, 2, sd),
              100 * colSums(counts_df > 0) / nrow(counts_df))
rownames(m_sd) = c("mean", "standard deviation", "% compounds with count > 0")
pandoc.table(m_sd, style = "rmarkdown")
```

We plot, for each of the considered elements, the distribution of the number of 
atoms of the given element in the compounds of HMDB.

```{r distribution-counts, fig.cap = "Distribution of the number of atoms of CHNOPS elements in compounds of HMDB.", fig.width = 7, fig.height = 14, echo = FALSE}
par(mfrow = c(7, 1), mar = c(3, 4, 1, 0.5))
for (el in CHNOPS) {
  hist(counts_df[, el], xlab = "", main = el, breaks = 256)
  abline(v = quantile(counts_df[, el], c(0.025, 0.975)))
}
```
## Isotopes

We focus here on elements which have isotopes (which excludes P) and for which 
the natural occurrence of the heavier isotopes isn't too low (which excludes H).

The presence of heavier elemental isotopes in a compound will result in a mass 
difference md with respect to the monoisotopic mass of the compound.
Although for each element, each isotope species is characterized by a difference 
of one or more neutrons the difference in mass between them 
isn't exactly integer and each elemental isotope will contribute in a different way 
producing different overall mass differences. 

In a compound with nX atoms of element X it is possible that nX1, nX2, ..., nXq 
(nX1+nX2+ ... +nXq = nX) atoms of X have isotope form 1, 2, ... q. Each configuration
CX = (nX1, nX2, ..., nXq) will result in a different shift in mass md_CX. 
The probability P(CX) of observing 
such a configuration (and the related mass shift md_CX) con be computed using the multinomial distribution.
The overall mass difference md with respect to the monoisotopic mass is determined by
the configurations of each element X, Y,... Z in the molecule i.e. by C = (CX, CY... CZ) 
and is given by the sum md = md_CX+ md_CY ... +md_CZ. Finally the probability of observing the 
overall configuration C (and the corresponding mass difference
md) is P(C) = P(md) = P(CX)* P(CY)...*P(CZ) i.e the product of the probability of observing the 
configurations related to each element.
To determine isotope groups in a spectrum we loop over its peaks. We consider the current peak
and suppose it is the monoisotopic peak of a certain compound. We then find peaks that 
have a mzd compatible with some of the possible sums md = md_CX+ md_CY ... +md_CZ.
We finally determine if these peaks are actually compatible with the intensity Ic_0
of the current peak (assumed to be monoisotopic peak of a certain compound) and if so 
we group them together as a isotopic group. To check the such compatibility we can 
proceed as follows.
In a isotope group spectrum the intensity I_md of the peak associated to md is 
of course equal to I_md/I_0*I_0 where I_0 is the intensity associated to the monoisotopic mass. 
Since I_md/I_0 approximates P(md)/P(0) we can check the compatibility of the candidate 
peak intensity Ic_md with Ic_0*P(md)/P(0).

There is a very high number N_CX of possible configurations CX (,CY...,CZ) 
for the atoms of X (,Y...,Z) and a even greater number N_CX* NCY...*NCZ of overall 
configurations C=(CX, CY..., CZ). Here we keep only those that are significant 
for our purpose.

For now we considered the following configurations of the isotopes of C, N, O, S, Cl

((nC-1,1), (nN, 0), (nO, 0, 0), (nS, 0, 0), (nCl,0)) corresponding to the "C13" case
((nC-2,2), (nN, 0), (nO, 0, 0), (nS, 0, 0), (nCl,0)) corresponding to the "2C13" case
((nC, 0), (nN, 0), (nO-1, 1, 0), (nS, 0, 0), (nCl,0)) corresponding to the "O17" case
((nC, 0), (nN, 0), (nO-1, 0, 1), (nS, 0, 0), (nCl,0)) corresponding to the "O18" case
...
et cetera.

How did we selected these? 

I don't know if I complicated things too much but I think that it is good to have 
the general case clear before doing simplifications or leave the things as they
currently are.

In the following, for now, I will sometimes leave the old terminology.  
to refer to the previously introduced configurations
with the term isotopes isotopes like we did before although they are not the same thing.

We next define the (**single charged**) isotopes which we will consider along
with their natural occurring relative abundance.


```{r}
isotopes <- data.frame(
    element = c("C", "C", "N", "O", "O", "S", "S", "Cl"),
    isotope = c("C13", "2C13", "N15", "O17", "O18", "S33", "S34", "Cl37"),
    number_neutrons = c(1, 1, 1, 1, 2, 1, 2, 1),
    number_isotopes = c(1, 2, 1, 1, 1, 1, 1, 1),
    mass_diff = c(1.00335484, 2.00670968, 0.997034965599999, 1.0042168777,
                  2.0042457777, 0.999387810000002, 1.99579614, 1.99704989),
    element_abundances = I(list(c(0.9893, 0.0107), 
                                c(0.9893, 0.0107),
                                c(0.99636, 0.00364),
                                c(0.99757, 0.00038, 0.00205), 
                                c(0.99757, 0.00038, 0.00205),
                                c(0.9499, 0.0075, 0.0425), 
                                c(0.9499, 0.0075, 0.0425),
                                c(0.7576, 0.2424))),
    whch = I(list(c(1), c(3), c(1), c(1, 0), c(0, 1), c(1,0), c(0,1), c(1)))
)
```

<!---The table below lists the defined isotopes.--->

```{r, echo = FALSE, results = "asis"}
# pandoc.table(isotopes, style = "rmarkdown",
#              caption = "Isotope definitions.")
```

More generic definitions
Here we define the elements we consider together with the natural abundances 
of their isotopic forms. We also define a list of overall configurations (or isotopes, if we want to use the previous terminology).
Let (CX,CY,...,CZ) be an overall configuration. If for example CY is (nY,0,...,0) we don't report CY in the list.
For CY we report only (nY2, nY2, ..., nYq). nX1 will be determined as nY-(nY2...+nYq)
More precisely for a group of nX atoms of X having isotope forms 1,2...q we only report the numbers 
the number of elements When only an element is 
specifie
```{r}
elements <- list(C = c(0.9893, 0.0107),
                 N = c(0.99636, 0.00364),
                 O = c(0.99757, 0.00038, 0.00205),
                 S = c(0.9499, 0.0075, 0.0425),
                 Cl = c(0.7576, 0.2424))

# Here I provide only the values for the ... the others are assumed to be 0
confs <- list(C13 = list(C = c(1)),
              `2C13` = list(C = c(2)),
              N15 = list(N = c(1)),
              O17 = list(O = c(1,0)),
              O18 = list(O = c(0, 1)),
              S33 = list(S = c(1,0)),
              S34 = list(S = c(0,1)),
              Cl37 = list(Cl = c(1)),
              C13O18 = list(C = c(1), O = c(0, 1)))
```

```{r}
elements_md <- list(C = c(1.00335484),
                 N = c(0.997034965599999),
                 O = c(1.0042168777, 2.0042457777),
                 S = c(0.999387810000002, 1.99579614),
                 Cl = c(1.99704989))
getmd <- function(conf, elements_md) 
  sum(sapply(names(conf), function(el) sum(conf[[el]]*elements_md[[el]])))
md_confs <- sapply(confs, function(conf) getmd(conf, elements_md))
```


## Computation of elemental probabilities
We below compute for each molecule in HMDB the probability that the molecule has 
a certain number (e.g. 1) of isotopes of a given element. Note that we drop
below the count for *H* because the natural occurrence of it's isotope(s) is too
low.

Here we consider the compounds in HMBD. We have already computed the counts of 
C for each of them. We compute the probability that among the the nC atoms of C
of a given compound 1 is C13 and the other nC-1 are C12.
This is not the probability of observing the md difference mC13 - mC12.
This is given by the P0 of other elements in the molecule. Since the P0 are less than
one the the above probability represent an upper bound for the probability of observing 
a given md. Could maybe be used to decide which configurations to take into account.

```{r}
#' Simple helper function to calculate probabilities from counts
prob_from_counts <- function(x, def) {
    res <- lapply(seq_len(nrow(def)), function(i) {
        niso <- sum(def$whch[[i]])
        sapply(x[, def$element[i]], function(n)
            ifelse(n > (niso - 1),
                   dmultinom(c(n - niso, def$whch[[i]]),
                             prob = def$element_abundances[[i]]), 0))
    })
    res <- do.call(cbind, res)
    colnames(res) <- def$isotope
    res
}
prob_df <- prob_from_counts(counts_df[, unique(isotopes$element)], isotopes)
# prob_df_2 <- cbind(
#     `C13` = sapply(counts_df$C, function(n)
#         ifelse(n > 0, dmultinom(c(n - 1, 1), prob = isotopes_2$C), 0)),
#     `2C13` = sapply(counts_df$C, function(n)
#         ifelse(n > 1, dmultinom(c(n - 2, 2), prob = isotopes_2$C), 0)),
#     `N15` = sapply(counts_df$N, function(n)
#         ifelse(n > 0, dmultinom(c(n - 1, 1), prob = isotopes_2$N), 0)),
#     `O17` = sapply(counts_df$O, function(n)
#         ifelse(n > 0, dmultinom(c(n - 1, 1, 0), prob = isotopes_2$O), 0)),
#     `O18` = sapply(counts_df$O, function(n)
#         ifelse(n > 0, dmultinom(c(n - 1, 0, 1), prob = isotopes_2$O), 0)),
#     `S33` = sapply(counts_df$S, function(n)
#         ifelse(n > 0, dmultinom(c(n - 1, 1, 0), prob = isotopes_2$S), 0)),
#     `S34` = sapply(counts_df$S, function(n)
#         ifelse(n > 0, dmultinom(c(n - 1, 0, 1), prob = isotopes_2$S), 0)),
#     `Cl37` = sapply(counts_df$Cl, function(n)
#         ifelse(n > 0, dmultinom(c(n - 1, 1), prob = isotopes_2$Cl), 0)))
```

```{r, fig.width = 7, fig.height = 20, fig.cap = "Distribution of probabilities for a certain isotope."}
par(mfrow = c(ncol(prob_df), 2), mar = c(2, 4, 1, 0.5))
for (name in colnames(prob_df)) {
  hist(prob_df[, name], probability = TRUE, main = name, xlab = "", breaks = 64)
  boxplot(prob_df[, name], main = name)
  #print(paste0(name," : ", quantile(v, 0.8)))
}
```

## Define lower and upper intensity ratio between candidate isotope peaks and the monoisotopic peak

We next define a lower and upper bound for the ratio between a candidate isotopic 
peak and the assumed monoisotopic peak. This will be used to decide weather the two
can be grouped together in an isotopic group or not.

In order to do this we compute this ratio RI_md for the compounds in HMDB and for each md.
Let be (CX,CY,...CZ) the overall configuration related to the mass difference md.
Then RI_md = P(md)/P(0) = P(CX)* P(CY)... * P(CZ)/(P((nX,0...,0))* P((nY,0...,0))... *P((nZ,0...,0))).
In all the cases we consider, many simplifications occur between numerator and denominator terms.

We define some helper functions to do the previous computations.
```{r}
P <- function(n, whch, prob){
  n0 <- n - sum(whch)
  sapply(n0, function(n0_) ifelse(n0_ >= 0, dmultinom(c(n0_, whch), prob = prob), 0))
}

# P(c(92, 93, 94), isotopes$whch[[1]], isotopes$element_abundances[[1]])

RI <- function(n, conf, elements){
  if(is.vector(n)) n <- as.matrix(n)
  el_names <- names(conf)
  res <- lapply(seq_along(conf), function(i){
    conf0_el <- rep(0, length(conf[[i]]))
    P(n[, i], conf[[i]], elements[[el_names[i]]])/P(n[, i], conf0_el, elements[[el_names[i]]])
  })
  if(length(res)==1)  res[[1]]
  else  do.call("*", res)
}

# #RI e P for carbon
# n <- 0:250
# plot(n, RI(n, list(C=c(1)), elements))
# points(n, P(n, c(1), elements$C),col="blue")
# #RI e P for H
# n <- 0:250
# pH2 <- 1-0.99988
# plot(n, n*pH2/(1-pH2))
# points(n, P(n, c(1), c(1-pH2,pH2)),col="blue")
# #temp <- RI(expand.grid(n,n)
```

We do the computation for each eleme
```{r}
RI_from_counts <- function(counts, confs, elements){
  do.call(cbind, lapply(confs, function(conf) RI(counts[, names(conf)], 
                                                 conf, elements)))}
RI_df <- RI_from_counts(counts_df, confs, elements)
```

RI_md depends on the numeber of atoms of C, N, P, S, O
```{r}
count_limits <- apply(counts_df, 2, quantile, probs = c(0.025, 0.975))
```

We next define for these lower and upper element bounds the bounds on RI

```{r}
#prob_limits <- prob_from_counts(count_limits, isotopes)
RI_limits <- RI_from_counts(count_limits,confs,elements)
```



This approach has the following limitations, mostly because it is based on all
compounds in HMDB regardless of their mass:
- the lower limit for C13 might be too large, because of the lower limit of
  carbon atom counts used (i.e. `r count_limits[1, "C"]`). The lower intensity
  threshold will be too large for all compounds with less C atoms.
- for *Cl37* both the lower and upper intensity limit is 0, thus we will never
  identify any such isotope.

```{r}
# prob_limits <- t(prob_limits)
# colnames(prob_limits) <- c("intensity_low", "intensity_high")
# isotopes <- cbind(isotopes, prob_limits)

RI_limits <- t(RI_limits)
colnames(RI_limits) <- c("intensity_low", "intensity_high")
isodef <- data.frame(name = names(confs), mass_diff = md_confs, RI_limits)

dr <- paste0("data/txt/isotope-intensity-estimation/")
dir.create(dr, showWarnings = FALSE, recursive = TRUE)
write.table(isotopes, file = paste0(dr, "hmdb_isotopes_constant_range.txt"),
            sep = "\t", row.names = FALSE)
```

TODO:

- [ ] Should we consider to lower the count for C13 (i.e. set it manually to 1)?
- [ ] For Cl37, should we increase the upper count?
- [ ] Should we use the `range` instead of the quantiles?

<!--- If I understand your question correctly using the range is equivalent to 
the extreme case of using quantiles 0 and 1. This would allow us to create bounds
that are fulfilled by all elements in HMBD. The side effect is that we would end 
up with larger intervals and as a result of that we would be less able to 
discriminate if the candidate peak is good. For example, imagine the current peak
having intensity 1000 is related to a compound with 50 atoms of carbon. In this case 
RI for the C13 configuration would be 0.5407864 meaning the candidate peak should 
be around 541 in intensity. But imagine the candidate peak we are checking is 50
in intensity. If we chose to use the range or very high quantiles, the bounds would 
be so large that we would accept the 50 intensity peak even though the expected intensity
is around 541. So there is a trade off between choosing extreme quantiles (in this 
case the probability of not classifying a correct peak is very low, but it is higher the 
probability of classifying a wrong peak) and choosing less extreme ones (in this 
case the probability of not classifying a correct peak is higher, but it is lower the 
probability of classifying a wrong peak). We would have to find the right 
compromise between the two errors based maybe on which one of the two we consider 
less important  ---->


## Define mass-dependent lower and upper intensity limits

The higher the compounds mass the larger the number of its atoms and hence also
the probability of an isotope of a specific element.

We next evaluate what the relationship between the compound's mass and its
number of specific atoms. We could use this later to determine a mass-dependent
factor to estimate the expected intensity of a certain isotope.

We try to fit a regression line for masses of molecules versus the number of 
atoms for the elements C, N, O, S, Cl.

```{r, fig.width = 7, fig.height = 20}
par(mfrow = c(5, 1), mar = c(3, 4, 1, 0.5))
for (el in c("C", "N" , "O", "S", "Cl")) {
counts_el <- counts_df[, el]
exactmass <- cmps$exactmass
# idx <- which(counts_df[, el] > 0 )#& exactmass<300)
# counts_el <- counts_el[idx]
# exactmass <- exactmass[idx]

lm <- lm(counts_el ~ exactmass)
plot(counts_el ~ exactmass, ylab = "counts", xlab = "exactmass", main = el)
abline(lm , col = "red")
}
```

```{r}
# A closer look on C. Attempt to find prediction intervals, but the hypoteses behind
# regression are not fulfilled so this approach probably doesn't make much sense
# countsC <- counts_df[, "C"]
# exactmass <- cmps$exactmass
# lmC <- lm(countsC ~ exactmass)
# 
# #summary(lmC)
# # plot(hist(residuals(lmC), breaks = 100))
# # shapiro.test(sample(residuals(lmC), size = 5000))
# # the residuals doesn't appear to be normal so this approach probably doesn't 
# # make sense
# 
# z0   <- data.frame(exactmass = seq(min(cmps$exactmass), max(cmps$exactmass), 
#                                    len = 1000))
# alpha = .05
# Conf <- predict.lm(lmC, z0, interval="confidence", level = 1 - alpha)
# Pred <- predict.lm(lmC, z0, interval="prediction", level = 1 - alpha)
# 
# plot(cmps$exactmass, countsC)
# lines(z0[, 1], Conf[, "fit"])
# lines(z0[, 1], Conf[, "lwr"], lty = 2, col = "red", lwd = 2)
# lines(z0[, 1], Conf[, "upr"], lty = 2, col = "red", lwd = 2)
# 
# lines(z0[, 1], Pred[, "lwr"], lty = 3, col = "gold", lwd=2)
# lines(z0[, 1], Pred[, "upr"], lty = 3, col = "gold", lwd=2)
```


```{r}
# Compute the slope of line through the origin and each (count, mass) point
slp <- counts_df/cmps$exactmass
q_slp <- apply(slp, 2, function(x) quantile(x, c(0.01, 0.999))) # values to be chosen
```

For each element we fit a regression to the points with top and low (?%) 
of the value of slp.
```{r, fig.width = 7, fig.height = 20}
#Iâ€™m not sure if maybe it would be best to fit a regression line through the 
# origin (i.e removing the intercept from the lm estimation).
slp_bounds <- list()
par(mfrow = c(5, 1), mar = c(3, 4, 1, 0.5))
for (el in c("C", "N" , "O", "S", "Cl")) {
high <- which(slp[, el] > q_slp[2, el])
low <- which(slp[, el] <= q_slp[1, el])
plot(cmps$exactmass, counts_df[, el], ylab = "counts", xlab = "exactmass", 
     main = el)
points(cmps$exactmass[low], counts_df[low, el], col = "green")
points(cmps$exactmass[high], counts_df[high, el], col = "blue")
lm_l <- lm(counts_df[low, el] ~ cmps$exactmass[low] -1)
lm <- lm(counts_df[, el] ~ cmps$exactmass -1)
lm_h <- lm(counts_df[high, el] ~ cmps$exactmass[high] -1 )
abline(lm_l, col)
abline(lm, col = "red")
abline(lm_h)

slp_bounds[[el]] <- c(low = unname(lm_l$coefficients), 
                        high = unname(lm_h$coefficients))
}
```
```{r}
slp_bounds <- data.frame(slp_bounds)
```

TODO

- [ ] decide how to define the lower and upper bound. Should we exclude count of
      0 (since if we look for an isotope of a certain element we (should) expect
      that the compound contains at least one atom - otherwise we would anyway
      not detect/find the isotope)?
- [ ] define intercept and slope for lower and upper bound (number of atoms
      depending on mass).
- [ ] isotope detection function: have a function that takes that and, given a
      mass (or m/z) calculates the lower and upper count of atoms and from that
      calculates the probability. The *isotope definition* `data.frame` should
      contain all the required information to perform that calculation and
      should be passed along to this function.



```{r}
get_RI_bound <- function(mass, slp_bounds){
  count_bounds <-  slp_bounds*mass 
  RI_from_counts(count_bounds, confs, elements)
}
```




# Session information

The R version and packages used in this analysis are listed below.

```{r sessioninfo}
sessionInfo()
```
