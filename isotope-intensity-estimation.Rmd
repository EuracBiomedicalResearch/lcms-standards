---
title: "Estimating isotope peak intensities for compounds defined in HMDB"
author: "Andrea Vicini, Johannes Rainer"
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    toc_depth: 3
    fig_width: 5
---

```{r style, echo = FALSE, results = 'asis', message = FALSE}
library(BiocStyle)
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

**Last modified:** `r file.info("isotope-intensity-estimation.Rmd")$mtime`<br />
**Compiled**: `r date()`

# Introduction

In this document we evaluate possibilities to estimate m/z and intensities for
isotopes without knowing the chemical formula for the compound. To this end we
analyze the element composition of all compounds in the human metabolome
database ([HMDB](https://hmdb.ca)).

The ultimate goal would be to have one or more functions that allow to identify
peaks in (MS1) spectra representing isotopes of the same compound based
exclusively on the m/z and intensity values, i.e. without knowing the chemical
formula of the compound. The functions should be modular and customizable and
should support low as well as high resolution instruments that would allow to
discriminate between isotope peaks from different elements.


# Isotope detection approaches


## `CAMERA`

[`CAMERA`](https://bioconductor.org/packages/release/bioc/html/CAMERA.html)
takes a simple approach based on hard coded lower and upper limits for isotope
peaks. How this limits were defined is unclear. For the m/z differences of the
peaks simple lower and upper limits are used, not discriminating between
e.g. C13 and N15 isotopes.

## `envipat`

[`envipat`](https://cran.r-project.org/web/packages/enviPat/) does not seem to
allow identifying isotopes in MS data but does predict an isotope (intensity)
distribution from a chemical formula.


## Breen et al. 2000. Automatic poisson peak harvesting for high throughput protein identification

The authors consider Poisson modelling of isotopic distributions. Given a 
molecule with mass m they find a mapping F between m and the mean M of the 
Poisson distribution model (F: m-> M).
To compute this mapping they derive from a database a hypothetical average 
aminoacid. Next they use this to construct a set of the theoretical peptides 
whose mass span a certain range of interest. They compute the isotopic 
distribution of those and for each one of them they compute M* as the value of M 
that makes Poisson(M) more similar to the isotopic distribution. Finally they 
fit a line for the values of m against the M* and this line represents the 
mapping F. In the end, they model the isotopic distribution of a compound with 
mass m as a Poisson(P(M))

## Park et al. 2008. Isotopic peak intensity ratio based algorithm for determination of isotopic clusters and monoisotopic masses of polypeptides from high-resolution mass spectrometric data

The following statements are reported for the isotopic distribution of a compound 
with elements C, H, N, O, S.
- the intensity of a peak Ik approximates to a polynomial in m (molecular weight) 
  with degree k
- the ratio between consecutive peaks (R) approximates to a linear function in m
- the ratio product between adjacent peaks (RP) approximates to a constant.

For the last two, the more m is big the better the above approximations get.

To find a relation between R and m they consider a large number of polypeptides 
in a certain database spanning a certain range (400-5200 Da) and for them 
they compute R. Then, the interval of interest is divided in two regions 
(at 1800 Da). For high masses a linear approximation is used and 
its coefficients are found by fitting a regression line whereas for low masses
they use a quotient of polynomials (with degree k+1 and k for the k-th R)

The algorithm to cluster isotopic peaks after peak peaking) involves:

- pseudocluster identification. It requires to loop over all the peaks and for
  each of them find groups of peaks starting with the current peak and separated
  by +1 (in the single charged case) for each peak. They first enumerate
  pseudoclusters with two peaks, then pseudoclusters with more peaks and then
  proceed by considering different charged states.
- isotopic cluster identification. Among the pseudoclusters, they identify
  isotopic clusters whose intensity patterns are similar to those of the
  isotopic distributions in terms of R and RP in the pseudocluster.
- duplicate cluster removal. In case two clusters overlap they remove the one
  whose most abundant peak is smaller. If the most abundant peaks are the same,
  the one with the lowest charge state is removed. If their charge states are
  also the same, the cluster with the lower "similarity score" is removed.

## Valkenborg et al. 2008. A Model-Based Method for the Prediction of the Isotopic Distribution of Peptides

Also in this article the authors consider the ratios between peak heights.
They model it as a polynomial model in m (monoisotopic mass) whose order 
is empirically determined by looking at the improvements obtained by adding 
higher order terms.
The parameters of the polynomial model are estimated using the least-squares 
method on different sets of theoretical peptides (and the model is valid in the 
corresponding mass range).
By comparing the ratios between a series of peaks observed in a spectrum with 
the ratios predicted from the model and selecting a treshold for the allowed 
"difference" they decide whether the series of peaks is part of an isotopic 
group or not.

## sgibb

As far as I have understood sgibb uses a mixed approach. He uses the approach of 
Park et al. 2008 but for checking if a candidate cluster is a isotope cluster, 
for which he uses the Poisson approach of Breen et al. 2000.


# Element counts in HMDB

In this section we analyze element compositions of compounds from the Human
Metabolome Database.

```{r libraries, warning = FALSE}
library("CompoundDb")
library("MetaboCoreUtils")
library("pander")
library(enviPat)
```

We load the HMDB database and extract the chemical formula and exact mass of all
compounds.

```{r}
cdb <- CompDb("data/CompDb.Hsapiens.HMDB.4.0.sqlite")
## cdb <- CompDb("~/CompDb.Hsapiens.HMDB.4.0.sqlite")
cmps <- compounds(cdb, columns = c("compound_id", "name",
                                   "formula", "exactmass"))
```

For each compound in the human metabolom database (HMDB) with available mass 
we compute how many atoms of C, H, N, O, P and S as well as Cl are present in it
(the latter is important because in human serum samples it is very likely that
Cl adducts are generated by electro spray ionization). 
We collect the counts in a data frame with a column for each element and a row 
for each compound in HMDB.

```{r}
cmps <- cmps[-which(is.na(cmps$exactmass)), ]
```

```{r}
CHNOPS <- c("C", "H", "N", "O", "P", "S", "Cl")
counts0 <- lapply(cmps$formula, function(frml) {
  res <- countElements(frml)
  row <- numeric(length(CHNOPS) + 1)
  names(row) <- c(CHNOPS, "onlyCHNOPS")
  only <- intersect(CHNOPS, names(res))
  row[only] <- res[only]
  row["onlyCHNOPS"] <- length(only) == length(res)
  row
  })
counts_df0 <- do.call(rbind, counts0)
rownames(counts_df0) <- cmps$compound_id
onlyCHNOPS <- counts_df0[, "onlyCHNOPS"]
counts_df <- data.frame(counts_df0[, CHNOPS])
```

From the `r nrow(counts_df)` compounds in HMDB 
`r sum(onlyCHNOPS != 1)` contain elements other than 
`r paste(CHNOPS, collapse = ",")`.

```{r}
# Here I excluded compounds that have elements different from CHNOPS because at 
# first I thought they could cause problems in the estimates. I'm still not 
# completely sure but maybe they can be added back
onlyCHNOPS <- as.logical(onlyCHNOPS)
cmps <- cmps[onlyCHNOPS, ]
counts_df <- counts_df[onlyCHNOPS, ]
```

We compute the mean and standard deviation for the number of each element in the
molecules of HMDB. For each element we also report the percentage of compounds 
which have at least one atom of the given element.

```{r, echo = FALSE, results = "asis"}
m_sd <- rbind(colMeans(counts_df), 
              apply(counts_df, 2, sd),
              100 * colSums(counts_df > 0) / nrow(counts_df))
rownames(m_sd) = c("mean", "standard deviation", "% compounds with count > 0")
pandoc.table(m_sd, style = "rmarkdown")
```

We plot, for each of the considered elements, the distribution of the number of 
atoms of the given element in the compounds of HMDB.

```{r distribution-counts, fig.cap = "Distribution of the number of atoms of CHNOPS elements in compounds of HMDB.", fig.width = 7, fig.height = 14, echo = FALSE}
par(mfrow = c(7, 1), mar = c(3, 4, 1, 0.5))
for (el in CHNOPS) {
  hist(counts_df[, el], xlab = "", main = el, breaks = 256)
  abline(v = quantile(counts_df[, el], c(0.025, 0.975)))
}
```

The most frequent elements in HMDB compounds are H, C and O, but while the
number of C and H atoms varies considerably and goes up to over 100, the maximal
number of O atoms if below 25. Also, the numbers of atoms for all other elements
is only very low. 


## Isotopes

We focus here on elements which have isotopes (which excludes P). 
$\require{mhchem}$

The presence of heavier elemental isotopes in a compound will result in a mass 
difference $md$ with respect to the monoisotopic mass of the compound.
Although for each element, each isotope species is characterized by a difference 
of one or more neutrons, the difference in mass between them isn't exactly 
integer and each elemental isotope will contribute in a different 
way producing different overall mass differences. 

In a compound with $n$ atoms of element $X$ ($n_X$) each of the atoms can be in
a specific isotope form $\ce{ ^{y}X }$ such as $\ce{^{12}C}$ or $\ce{^{13}C}$
(with the prevalence of each isotope form for each element being known). Each
combination of such isotopes $I_X$ (e.g. $\ce{3 ^{12}C}$ $\ce{2 ^{13}C}$ 
$\ce{4 ^{14}C}$ will result in a different shift in mass $md_{I_X}$. 
The probability $P(I_X)$ of observing such a combination of isotopes for an
element $X$ can be computed using the multinomial distribution. The overall mass
difference $md$ with respect to the monoisotopic mass is determined by the
combination (number and variant) of isotopes of each element $X, Y,... Z$ in the
molecule which defines the
(isotopologue)[https://en.wikipedia.org/wiki/Isotopologue] of the compound $I =
(I_X, I_Y... I_Z)$ and is given by the sum $md = md_{I_X}+ md_{I_Y}
... +md_{I_Z}$. Finally the probability of observing the isotopologue $I$ (and
the corresponding mass difference $md$) is $P(I) = P(md) = P(I_X)*
P(I_Y)...*P(I_Z)$ i.e. the product of the probability of observing each isotope
variant related to each element.

There is a very high number $N_{I_X} = \binom{q + n_X -1}{n_X}$ of possible
combinations of isotopes $I_X$ for the atoms of $X$ and a even greater number
$N_{I_X}* N_{I_Y}...*N_{I_Z}$ of possible isotopologues $I=(I_X, I_Y...,
I_Z)$. Here we keep only those that are significant for our purpose, i.e. that,
based on the isotope pattern calculated from the chemical formulas of all
compounds in HMDB, would result in an intensity that is higher than a specified
proportion of the monoisotopic peak M0. These are identified in the following
section.

## Identifying most common isotopologues

Here we try to determine which isotopologues are the most frequently observed in
human metabolomics based on all compounds from HMDB.

To this end we calculate the isotope pattern for each compound in HMDB using
`enviPat` and identify all isotopologues which would result in an intensity
higher than a certain proportion of the monoisotopic form. We get thus for each
compound all theoretical isotopologues that would result in an intensity higher
than the specified threshold (0.01% of the intensity from the monoisotopic
mass). For each of these peaks we define its *isotopologue id* which
consists of the observed isotopes for that compound, e.g. `"4[13C]2[15N]"` for
isotopologues of all compounds that contain this isotope composition.

```{r, echo = FALSE}
dr <- paste0("data/RData/isotope-intensity-estimation/")
dir.create(dr, showWarnings = FALSE, recursive = TRUE)
```

```{r, eval = !file.exists(paste0(dr, "subst_frequencies.RData"))}
data(isotopes)
## Ensure that element order is correct
chemforms <- sapply(cmps$formula, standardizeFormula)
threshold = 0.01
iso_ps <- isopattern(isotopes, chemforms , threshold = threshold)

## Process the isotope pattern to define a character string for each
## isotopologue - ensuring the order of isotopes to be the same across
## compounds
isos <- c("13C", "2H", "15N", "17O", "18O", "33S", "34S", "35S", "36S", 
          "36Cl", "37Cl")
subst_per_cmpd <- lapply(iso_ps, function(iso_p) {
    idx <- match(colnames(iso_p), isos)
    tmp <- iso_p[, !is.na(idx), drop = FALSE]
    tmp <- tmp[rowSums(tmp) > 0, order(idx[!is.na(idx)]), drop = FALSE]
    cn <- colnames(tmp)
    apply(tmp, 1, function(row)
        paste0(row[row >0], "[", cn[row > 0], "]", collapse = ""))
})
subst_frequency <- table(unlist(subst_per_cmpd, use.names = FALSE))

save(subst_frequency, subst_per_cmpd, file = paste0(dr, "subst_frequencies.RData"))
```

```{r, echo = FALSE, eval = file.exists(paste0(dr, "subst_frequencies.RData"))}
load(paste0(dr, "subst_frequencies.RData"))
```

```{r}
subst_proportion <- sort(subst_frequency / nrow(cmps), decreasing = TRUE)
par(mar = c(8, 4.1, 4.1, 2.1))
barplot(subst_proportion[subst_proportion > 0.5], las = 2)
```

In the plot above we can see isotopologues for compounds in HMBD that produce a
*significant* peak for at least a half of the compounds (the height of the bar
specifies the exact proportion). In other words, if we randomly sample a compund
in HMBD the chance to observe a significant peak related to the above
isotopologues will be high. I observe however that this approach penalizes
families related to elements with low counts in HMBD compounds. The number of
times a family related to N, S or Cl is found to be significant is limited by
the fact that the number of compounds in HMBD that contain these elements is
much lower than those that contain C, H, or O.

We thus next compare the isotopologue frequency not against the total number of
compounds in HMDB, but against the number of compounds in HMDB that contain each
of the elements from the isotopologue definition in their chemical formula.

```{r}
ncomps <- vapply(names(subst_frequency), function(x) {
    x <- unlist(strsplit(x, split = "\\]"))
    x <- gsub("[0-9\\[]+", "", x)
    ## require at least one element for each element in the
    ## isotopologue definition
    sum(rowSums(counts_df[, x, drop = FALSE] > 0) == length(x))
}, integer(1))
```

```{r, fig.height = 5, fig.width = 17}
subst_proportion_var <- sort(subst_frequency/ncomps, decreasing = TRUE)
par(mar = c(10, 4.1, 4.1, 2.1))
barplot(subst_proportion_var[subst_proportion_var > 0.5], las = 2)
```


Here I also try to divide the counts of the times a family is found to be 
significant in the HMBD compounds for the times that this family can be 
observed across the HMBD compounds. In other words these ratios represent the 
likelihood to find a family significant among the subset of HMBD compounds that 
have it as possible substitution (this happens when, for each element 
$X$ in the compound, the number of atoms of $X$ is >= than the sum of the 
numbers ${n_X}_2$, ..., ${n_X}_q$ of heavier isotopes associated to the 
substitution).

```{r}
count_heavy_iso <- function(subst_str)
{
  tmp <- strsplit(subst_str, "]")[[1]]
  names(tmp) <- sapply(tmp, function(s) strsplit(s, "\\[")[[1]][2])
  heavy_iso <- sapply(tmp, function(s) as.numeric(strsplit(s, "\\[")[[1]][1])) 
  tapply(heavy_iso, gsub('[0-9]+', '', names(heavy_iso)), sum)
}

nvar <- sapply(names(subst_frequency), function(subst) {
  els <- count_heavy_iso(subst)
  var <- rep(TRUE, nrow(counts_df))
  for (el in names(els)) 
    var <- var & (counts_df[, el] >= els[el])
  sum(var)
})
```


```{r, fig.height = 5, fig.width = 17}
subst_proportion_var <- sort(subst_frequency/nvar, decreasing = TRUE)[-1]
par(mar = c(10, 4.1, 4.1, 2.1))
barplot(subst_proportion_var[subst_proportion_var > 0.5], las = 2)
```

In the plot above we can see the substitutions that produce a significant 
peak for at least a half of the compounds in which they are possible. 
(the height of the bar specifies the exact proportion). In this case we observe 
also families where N, S or Cl in them. 
To exemplify the difference, all molecules (the proportion in the above plot is 
1) of HMBD that have at least 1 atom of C and 1 atom of Cl are found to have 
significant peaks corresponding to 1[13C]1[37Cl]. However, since the number of 
such compounds in HMBD is very low the probability of observing the effect of 
such a substitution is very very low if we randomly pick one compound in HMBD.

### Discussion

- [ ] m/z dependent isotopologues: check if the m/z matches ~ the mass of the
      isotopologue definition. Considering an isotopologue 9[13C]2[18O] would
      not make sense for an m/z that is lower than the mass of this
      isotopologue.

## Isotopes related definitions

Here I construct a list of substitutions based on the substitutions selected in 
the previous section. I convert each strings to a list (but we can also change 
this representation) as used by the functions in the rest of the file. 

```{r}
selected_names <- names(subst_proportion_var[subst_proportion_var > 0.5])
h_iso_forms <- list(C = c("13C"), H = c("2H"), N = c("15N"), O = c("17O", "18O"), 
                    S = c("33S", "34S", "36S"), Cl = c("37Cl"))

substs <- lapply(selected_names, function(name) {
  splt1 <- strsplit(name, "]")[[1]]
  subst_v <- sapply(splt1, function(s) as.numeric(strsplit(s, "\\[")[[1]][1]))
  names(subst_v) <- sapply(splt1, function(s) strsplit(s, "\\[")[[1]][2])
  elements <- gsub('[0-9]', '', names(subst_v))
  subst <- lapply(unique(elements), function(el) {
    el_subst_names <- h_iso_forms[[el]]
    el_subst <- rep(0, length(el_subst_names))
    names(el_subst) <- el_subst_names
    tmp <- subst_v[elements == el]
    el_subst[names(tmp)] <- tmp
    el_subst
  })
  names(subst) <- unique(elements)
  subst
})
names(substs) <- selected_names
```


We define the elements we consider together with the natural abundances 
of their isotopic forms. I also define mass differences of isotopes of each 
element and a simple function to get from them the md originated by a given 
substitution. 

```{r}
# Here I added H and 36S and the related information. I took the values from 
# envipat. I wonder why some values are known with more precision
elements_ab <- list(C = c(0.9893, 0.0107),
                    H = c(0.99988500, 0.00011500),
                    N = c(0.99636, 0.00364),
                    O = c(0.99757, 0.00038, 0.00205),
                    S = c(0.9499, 0.0075, 0.0425, 0.0001),
                    Cl = c(0.7576, 0.2424))

elements_md <- list(C = c(1.00335484),
                    H = c(1.006277), 
                    N = c(0.997034965599999),
                    O = c(1.0042168777, 2.0042457777),
                    S = c(0.999387810000002, 1.99579614, 3.027929),
                    Cl = c(1.99704989))

getmd <- function(subst, elements_md) 
  sum(sapply(names(subst), function(el) sum(subst[[el]] * elements_md[[el]])))
```

Here we compute the md for the considered substitutions.
```{r}
md_substs <- sapply(substs, function(subst) getmd(subst, elements_md))
```

## Define lower and upper intensity ratio between candidate isotope peaks and the monoisotopic peak

To determine isotope groups in a spectrum we loop over its peaks. We consider 
the current peak and suppose it is the monoisotopic peak of a certain compound. 
We then find peaks that have a mzd compatible with some of the possible sums 
$md = md_{C_X}+ md_{C_Y} ... +md_{C_Z}$.
We finally determine if these peaks are actually compatible with the intensity 
${Ic}_0$ of the current peak (assumed to be monoisotopic peak of a certain 
compound) and if so we group them together as a isotopic group. To check such 
compatibility we can proceed as follows.
In a isotope group spectrum the intensity $I_{md}$ of the peak associated to 
$md$ is of course equal to $I_{md}/ I_0*I_0$ where $I_0$ is the intensity 
associated to the monoisotopic mass. 
Since $I_{md}/ I_0$ approximates $P(md)/ P(0)$ we can check the compatibility of 
the candidate peak intensity ${Ic}_{md}$ with ${Ic}_0$* $P(md)/ P(0)$.

We next define a lower and upper bound for the ratio $R$ between a candidate 
isotopic peak and the assumed monoisotopic peak. This will be used to decide 
weather the two can be grouped together in an isotopic group or not.

Let be $(I_X,I_Y,...I_Z)$ the isotopologue of a compound related to the mass 
difference $md$. Then
$$R_{md} = \frac{P(md)}{P(0)} = \frac{P(I_X)* P(I_Y)... * P(I_Z)}
{P((n_X,0...,0))* P((n_Y,0...,0))... *P((n_Z,0...,0))}$$.
In all the cases we consider, many simplifications occur between numerator and 
denominator terms. As a result of that $R_md$ will depend only on the elemental 
isoltoplogues different from those of the $md = 0$ isotopologue of the 
monoisotopic peak.

We define some helper functions to do what we just described. 
`P` computes the probability of the elemental isotopologue (or how should we call 
$I_X$ etc?) of `c(n-sum(subst), subst)` related to the corresponding isotope probabilities 
in `prob`. It works also if `n`is a vector. In that case each value of `n` 
originates a different elemental isotopologue and the associated probabilities 
are returned as a vector.`R` computes the ratio between a given isotopologue
`subst` and and the isotopologue related to the md = 0 
(i.e the one related to the monoisotopic peak). `elements_ab` is the list of 
abundances of the isotopes of the considered elements.`n` is a matrix with 
`length(subst)` columns . Each row of n specifies the number of atoms of the 
considered elements in a given compound.

```{r}
P <- function(n, subst, prob){
  n0 <- n - sum(subst)
  sapply(n0, function(n0_) ifelse(n0_ >= 0, 
                                  dmultinom(c(n0_, subst), prob = prob), 0))
}

R <- function(n, subst, elements_ab){
  el_names <- names(subst)
  res <- lapply(seq_along(subst), function(i){
    subst0_el <- rep(0, length(subst[[i]]))
    P(n[, i], subst[[i]], elements_ab[[el_names[i]]])/
      P(n[, i], subst0_el, elements_ab[[el_names[i]]])
  })
  apply(do.call(rbind, res), 2, prod)
}

R_from_counts <- function(counts, substs, elements_ab){
  do.call(cbind, lapply(substs, function(subst) R(counts[, names(subst), 
                                                         drop = FALSE], 
                                                 subst, elements_ab)))}
```

As we saw, $R_{md}$ depends on the counts of elements in the compound. We can 
determine lower and upper bounds on those and then obtain the 
corresponding bounds on R. We consider two different approaches: one which 
considers what the count is for most elements of HMBD, the other which considers 
the counts of the elements in HMBD as dependent on the mass.

## Mass-independent bounds

For a given element $X$ we can determine two quantiles ${q_1}_X$ and ${q_2}_X$ 
such that a certain percentage (e.g 95%) of compounds in HMBD have 
${q_1}_X<n_X<{q_2}_X$ and repeat the same for all the elements. In this first 
approach we consider the obtained quantiles as the upper and lower bounds on 
counts.

```{r}
count_limits <- apply(counts_df, 2, quantile, probs = c(0.025, 0.975))
```

We next compute the corresponding bounds on $R$

```{r}
R_limits <- R_from_counts(count_limits, substs, elements_ab)
```

and save them in a txt file together with the names of the substitutions and
the related mass differences.

```{r}
R_limits <- t(R_limits)
colnames(R_limits) <- c("min_ratio", "max_ratio")
isodef <- data.frame(name = names(substs), mzd = md_substs, R_limits)
isodef <- isodef[order(isodef[, "mzd"]), ]

dr_txt <- paste0("data/txt/isotope-intensity-estimation/")
dir.create(dr, showWarnings = FALSE, recursive = TRUE)
write.table(isodef, file = paste0(dr_txt, "hmdb_isotopes_constant_range.txt"),
            sep = "\t", row.names = FALSE)
```

## Define mass-dependent bounds

We next evaluate what the relationship between the compound's mass and its
number of specific atoms. We use this later to determine a mass-dependent
factor to estimate the expected intensity of a certain isotope.

We try to fit a regression line for masses of molecules versus the number of 
atoms for the elements $C, N, O, S, Cl$ in the HMBD compounds. We expect in 
general to have higher counts of the elements for a higher mass. 

```{r, fig.width = 7, fig.height = 20}
par(mfrow = c(5, 1), mar = c(3, 4, 1, 0.5))
for (el in c("C", "N" , "O", "S", "Cl")) {
counts_el <- counts_df[, el]
exactmass <- cmps$exactmass
lm <- lm(counts_el ~ exactmass)
plot(counts_el ~ exactmass, ylab = "counts", xlab = "exactmass", main = el)
abline(lm , col = "red")
}
```
The regression doesn't appear to work very well apart from $C$ and maybe $O$. We 
try to construct two lines representing mass dependent lower and upper bounds for 
the counts. First, for each element, we compute the slope of the line through the 
origin and each (count, mass) point.

```{r}
slp <- counts_df/cmps$exactmass
q_slp <- apply(slp, 2, function(x) quantile(x, c(0.01, 0.999))) # values to be chosen
```

Then we fit a regression to the points with top and low (?%) of the value of the 
slope (actually, in principle we could directly use the value of the quantile as 
a value of the slope of the lower/upper bound line). We plot the results, 
store the values of the slopes.

```{r, fig.width = 7, fig.height = 20}
slp_bounds <- list()
par(mfrow = c(5, 1), mar = c(3, 4, 1, 0.5))
for (el in c("C", "H", "N" , "O", "S", "Cl")) {
high <- which(slp[, el] > q_slp[2, el])
low <- which(slp[, el] <= q_slp[1, el])
plot(cmps$exactmass, counts_df[, el], ylab = "counts", xlab = "exactmass", 
     main = el)
points(cmps$exactmass[low], counts_df[low, el], col = "green")
points(cmps$exactmass[high], counts_df[high, el], col = "blue")
lm_l <- lm(counts_df[low, el] ~ cmps$exactmass[low] -1)
lm <- lm(counts_df[, el] ~ cmps$exactmass -1)
lm_h <- lm(counts_df[high, el] ~ cmps$exactmass[high] -1 )
abline(lm_l, col)
abline(lm, col = "red")
abline(lm_h)

slp_bounds[[el]] <- c(low = unname(lm_l$coefficients), 
                        high = unname(lm_h$coefficients))
}
```

and save them to a txt file.

```{r}
slp_bounds <- data.frame(slp_bounds)
```

Here we try to exclude the points with count = 0. This can be justified by the
following fact. Suppose that in a spectrum the mass difference between a peak 
and the assumed monoisotopic peak is matched to a certain $md$. We know 
that $md$ is associated to a certain substitution and therefore to a
certain number of heavier isotopic forms of certain elements. It follows that if 
the candidate peak is from the isotopic pattern it must have at least a number of 
each element equal to the sum of the numbers of heavier isotopic form in the 
substitution.

```{r}
# Based on the plots, we could decide to use different quantiles for each element
pq <- data.frame(C = c(0.01, 0.99),
                 H = c(0.01, 0.99),
                 N = c(0.01, 0.99),
                 O = c(0.01, 0.99),
                 P = c(0.01, 0.99),
                 S = c(0.01, 0.99),
                 Cl = c(0.01, 0.99))
pos_idxs <- apply(counts_df, 2, function(col) unname(which(col > 0)))
q_slp2 <- lapply(names(pos_idxs), function(el) quantile(slp[pos_idxs[[el]], el], 
                                                        pq[, el]))
q_slp2 <- do.call(cbind, q_slp2)
colnames(q_slp2) <- names(pos_idxs)
```

Then we fit a regression to the points with top and low (?%) of the value of the 
slope.

```{r, fig.width = 7, fig.height = 20}
slp_bounds2 <- list()
par(mfrow = c(6, 1), mar = c(3, 4, 1, 0.5))
for (el in c("C", "H", "N" , "O", "S", "Cl")) {
high <- intersect(which(slp[, el] > q_slp2[2, el]), pos_idxs[[el]])
low <- intersect(which(slp[, el] <= q_slp2[1, el]), pos_idxs[[el]])
plot(cmps$exactmass[pos_idxs[[el]]], counts_df[pos_idxs[[el]], el], 
     ylab = "counts", xlab = "exactmass", main = el, 
     ylim = c(0, max(counts_df[pos_idxs[[el]], el])))
points(cmps$exactmass[low], counts_df[low, el], col = "green")
points(cmps$exactmass[high], counts_df[high, el], col = "blue")
lm_l <- lm(counts_df[low, el] ~ cmps$exactmass[low] -1)
lm_h <- lm(counts_df[high, el] ~ cmps$exactmass[high] -1 )
abline(lm_l, col)
abline(lm_h)

slp_bounds2[[el]] <- c(low = unname(lm_l$coefficients), 
                        high = unname(lm_h$coefficients))
}
```

Here is a first tentative function to get the bounds on R for a specific mass
```{r}
get_R_bound <- function(mass, slp_bounds){
  count_bounds <-  slp_bounds*mass 
  R_from_counts(count_bounds, substs, elements_ab)
}
```

```{r}
slope_bounds <- do.call(rbind, slp_bounds2)
write.table(slope_bounds, file = paste0(dr_txt, "slope_bounds.txt"),
            sep = "\t", row.names = TRUE)
```

# Session information

The R version and packages used in this analysis are listed below.

```{r sessioninfo}
sessionInfo()
```
