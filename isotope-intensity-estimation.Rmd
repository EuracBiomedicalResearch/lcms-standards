---
title: "Estimating isotope peak intensities for compounds defined in HMDB"
author: "Andrea Vicini, Johannes Rainer"
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    toc_depth: 3
    fig_width: 5
---

```{r style, echo = FALSE, results = 'asis', message = FALSE}
library(BiocStyle)
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

**Last modified:** `r file.info("isotope-intensity-estimation.Rmd")$mtime`<br />
**Compiled**: `r date()`

# Introduction

In this document we evaluate possibilities to estimate m/z and intensities for
isotopes without knowing the chemical formula for the compound. To this end we
analyze the element composition of all compounds in the human metabolome
database ([HMDB](https://hmdb.ca)).

The ultimate goal would be to have one or more functions that allow to identify
peaks in (MS1) spectra representing isotopes of the same compound based
exclusively on the m/z and intensity values, i.e. without knowing the chemical
formula of the compound. The functions should be modular and customizable and
should support low as well as high resolution instruments that would allow to
discriminate between isotope peaks from different elements.


# Isotope detection approaches


## `CAMERA`

[`CAMERA`](https://bioconductor.org/packages/release/bioc/html/CAMERA.html)
takes a simple approach based on hard coded lower and upper limits for isotope
peaks. How this limits were defined is unclear. For the m/z differences of the
peaks simple lower and upper limits are used, not discriminating between
e.g. C13 and N15 isotopes.

## `envipat`

[`envipat`](https://cran.r-project.org/web/packages/enviPat/) does not seem to
allow identifying isotopes in MS data but does predict an isotope (intensity)
distribution from a chemical formula.


## Breen et al. 2000. Automatic poisson peak harvesting for high throughput protein identification

The authors consider Poisson modelling of isotopic distributions. Given a 
molecule with mass m they find a mapping F between m and the mean M of the 
Poisson distribution model (F: m-> M).
To compute this mapping they derive from a database a hypothetical average 
aminoacid. Next they use this to construct a set of the theoretical peptides 
whose mass span a certain range of interest. They compute the isotopic 
distribution of those and for each one of them they compute M* as the value of M 
that makes Poisson(M) more similar to the isotopic distribution. Finally they 
fit a line for the values of m against the M* and this line represents the 
mapping F. In the end, they model the isotopic distribution of a compound with 
mass m as a Poisson(P(M))

## Park et al. 2008. Isotopic peak intensity ratio based algorithm for determination of isotopic clusters and monoisotopic masses of polypeptides from high-resolution mass spectrometric data

The following statements are reported for the isotopic distribution of a compound 
with elements C, H, N, O, S.
- the intensity of a peak Ik approximates to a polynomial in m (molecular weight) 
  with degree k
- the ratio between consecutive peaks (R) approximates to a linear function in m
- the ratio product between adjacent peaks (RP) approximates to a constant.

For the last two, the more m is big the better the above approximations get.

To find a relation between R and m they consider a large number of polypeptides 
in a certain database spanning a certain range (400-5200 Da) and for them 
they compute R. Then, the interval of interest is divided in two regions 
(at 1800 Da). For high masses a linear approximation is used and 
its coefficients are found by fitting a regression line whereas for low masses
they use a quotient of polynomials (with degree k+1 and k for the k-th R)

The algorithm to cluster isotopic peaks after peak peaking) involves:

- pseudocluster identification. It requires to loop over all the peaks and for
  each of them find groups of peaks starting with the current peak and separated
  by +1 (in the single charged case) for each peak. They first enumerate
  pseudoclusters with two peaks, then pseudoclusters with more peaks and then
  proceed by considering different charged states.
- isotopic cluster identification. Among the pseudoclusters, they identify
  isotopic clusters whose intensity patterns are similar to those of the
  isotopic distributions in terms of R and RP in the pseudocluster.
- duplicate cluster removal. In case two clusters overlap they remove the one
  whose most abundant peak is smaller. If the most abundant peaks are the same,
  the one with the lowest charge state is removed. If their charge states are
  also the same, the cluster with the lower "similarity score" is removed.

## Valkenborg et al. 2008. A Model-Based Method for the Prediction of the Isotopic Distribution of Peptides

Also in this article the authors consider the ratios between peak heights.
They model it as a polynomial model in m (monoisotopic mass) whose order 
is empirically determined by looking at the improvements obtained by adding 
higher order terms.
The parameters of the polynomial model are estimated using the least-squares 
method on different sets of theoretical peptides (and the model is valid in the 
corresponding mass range).
By comparing the ratios between a series of peaks observed in a spectrum with 
the ratios predicted from the model and selecting a treshold for the allowed 
"difference" they decide whether the series of peaks is part of an isotopic 
group or not.

## sgibb

As far as I have understood sgibb uses a mixed approach. He uses the approach of 
Park et al. 2008 but for checking if a candidate cluster is a isotope cluster, 
for which he uses the Poisson approach of Breen et al. 2000.


# Element counts in HMDB

In this section we analyze element compositions of compounds from the Human
Metabolome Database.

```{r libraries, warning = FALSE}
library("CompoundDb")
library("MetaboCoreUtils")
library("pander")
library(enviPat)
```

We load the HMDB database and extract the chemical formula and exact mass of all
compounds.

```{r}
cdb <- CompDb("data/CompDb.Hsapiens.HMDB.4.0.sqlite")
## cdb <- CompDb("~/CompDb.Hsapiens.HMDB.4.0.sqlite")
cmps <- compounds(cdb, columns = c("compound_id", "name",
                                   "formula", "exactmass"))
```

For each compound in the human metabolom database (HMDB) with available mass 
we compute how many atoms of C, H, N, O, P and S as well as Cl are present in it
(the latter is important because in human serum samples it is very likely that
Cl adducts are generated by electro spray ionization). 
We collect the counts in a data frame with a column for each element and a row 
for each compound in HMDB.

```{r}
cmps <- cmps[-which(is.na(cmps$exactmass)), ]
```

```{r}
CHNOPS <- c("C", "H", "N", "O", "P", "S", "Cl")
counts0 <- lapply(cmps$formula, function(frml) {
  res <- countElements(frml)
  row <- numeric(length(CHNOPS) + 1)
  names(row) <- c(CHNOPS, "onlyCHNOPS")
  only <- intersect(CHNOPS, names(res))
  row[only] <- res[only]
  row["onlyCHNOPS"] <- length(only) == length(res)
  row
  })
counts_df0 <- do.call(rbind, counts0)
rownames(counts_df0) <- cmps$compound_id
onlyCHNOPS <- counts_df0[, "onlyCHNOPS"]
counts_df <- data.frame(counts_df0[, CHNOPS])
```

From the `r nrow(counts_df)` compounds in HMDB 
`r sum(onlyCHNOPS != 1)` contain elements other than 
`r paste(CHNOPS, collapse = ",")`.

```{r}
# Here I excluded compounds that have elements different from CHNOPS because at 
# first I thought they could cause problems in the estimates. I'm still not 
# completely sure but maybe they can be added back
onlyCHNOPS <- as.logical(onlyCHNOPS)
cmps <- cmps[onlyCHNOPS, ]
counts_df <- counts_df[onlyCHNOPS, ]
```

We compute the mean and standard deviation for the number of each element in the
molecules of HMDB. For each element we also report the percentage of compounds 
which have at least one atom of the given element.

```{r, echo = FALSE, results = "asis"}
m_sd <- rbind(colMeans(counts_df), 
              apply(counts_df, 2, sd),
              100 * colSums(counts_df > 0) / nrow(counts_df))
rownames(m_sd) = c("mean", "standard deviation", "% compounds with count > 0")
pandoc.table(m_sd, style = "rmarkdown")
```

We plot, for each of the considered elements, the distribution of the number of 
atoms of the given element in the compounds of HMDB.

```{r distribution-counts, fig.cap = "Distribution of the number of atoms of CHNOPS elements in compounds of HMDB.", fig.width = 7, fig.height = 14, echo = FALSE}
par(mfrow = c(7, 1), mar = c(3, 4, 1, 0.5))
for (el in CHNOPS) {
  hist(counts_df[, el], xlab = "", main = el, breaks = 256)
  abline(v = quantile(counts_df[, el], c(0.025, 0.975)))
}
```

The most frequent elements in HMDB compounds are H, C and O, but while the
number of C and H atoms varies considerably and goes up to over 100, the maximal
number of O atoms if below 25. Also, the numbers of atoms for all other elements
is only very low. 


## Isotopes

We focus here on elements which have isotopes (which excludes P). 
$\require{mhchem}$

The presence of heavier elemental isotopes in a compound will result in a mass 
difference $md$ with respect to the monoisotopic mass of the compound.
Although for each element, each isotope species is characterized by a difference 
of one or more neutrons, the difference in mass between them isn't exactly 
integer and each elemental isotope will contribute in a different 
way producing different overall mass differences. 

In a compound with $n$ atoms of element $X$ ($n_X$) each of the atoms can be in
a specific isotope form $\ce{ ^{y}X }$ such as $\ce{^{12}C}$ or $\ce{^{13}C}$
(with the prevalence of each isotope form for each element being known). Each
combination of such isotopes $I_X$ (e.g. $\ce{3 ^{12}C}$ $\ce{2 ^{13}C}$ 
$\ce{4 ^{14}C}$ will result in a different shift in mass $md_{I_X}$. 
The probability $P(I_X)$ of observing such a combination of isotopes for an
element $X$ can be computed using the multinomial distribution. The overall mass
difference $md$ with respect to the monoisotopic mass is determined by the
combination (number and variant) of isotopes of each element $X, Y,... Z$ in the
molecule which defines the
(isotopologue)[https://en.wikipedia.org/wiki/Isotopologue] of the compound $I =
(I_X, I_Y... I_Z)$ and is given by the sum $md = md_{I_X}+ md_{I_Y}
... +md_{I_Z}$. Finally the probability of observing the isotopologue $I$ (and
the corresponding mass difference $md$) is $P(I) = P(md) = P(I_X)*
P(I_Y)...*P(I_Z)$ i.e. the product of the probability of observing each isotope
variant related to each element.

There is a very high number $N_{I_X} = \binom{q + n_X -1}{n_X}$ of possible
combinations of isotopes $I_X$ for the atoms of $X$ and a even greater number
$N_{I_X}* N_{I_Y}...*N_{I_Z}$ of possible isotopologues $I=(I_X, I_Y...,
I_Z)$. Here we keep only those that are significant for our purpose, i.e. that,
based on the isotope pattern calculated from the chemical formulas of all
compounds in HMDB, would result in an intensity that is higher than a specified
proportion of the monoisotopic peak M0. These are identified in the following
section.

<!-- @andrea: you are now defining these "families" based on HMDB and no longer -->
<!-- manually, right? Then we can skip the text below. -->
<!-- We define family of configurations as the sets of configurations that share the  -->
<!-- same number of heavier isotopes for each element and therefore the same mass  -->
<!-- difference with respect to the monoisotopic mass. -->
<!-- For now we considered the following families of configurations related the  -->
<!-- isotopes of $C, N, O, S, Cl$ -->

<!-- $((n_C-1,1), (n_N, 0), (n_O, 0, 0), (n_S, 0, 0), (n_{Cl},0))$ corresponding to  -->
<!-- the "C13" case -->

<!-- $((n_C-2,2), (n_N, 0), (n_O, 0, 0), (n_S, 0, 0), (n_{Cl},0))$ corresponding to  -->
<!-- the "2C13" case -->

<!-- $((n_C, 0), (n_N, 0), (n_O-1, 1, 0), (n_S, 0, 0), (n_{Cl},0))$ corresponding to  -->
<!-- the "O17" case -->

<!-- $((n_C, 0), (n_N, 0), (n_O-1, 0, 1), (n_S, 0, 0), (n_{Cl},0))$ corresponding to  -->
<!-- the "O18" case -->

<!-- ... -->
<!-- et cetera. -->

<!-- For example ((5,1), (4, 0), (3, 0, 0), (2, 0, 0), (1,0)) and  -->
<!-- ((1,1), (2, 0), (3, 0, 0), (4, 0, 0), (5,0)) are both in the "C13" family and  -->
<!-- correspond to the md: mass of C13 - mass of C12 -->


## Identifying most common isotopologues

Here we try to determine which isotopologues are the most frequently observed in
human metabolomics based on all compounds from HMDB.

To this end we calculate the isotope pattern for each compound in HMDB using
`enviPat` and identify all isotopologues which would result in an intensity
higher than a certain proportion of the monoisotopic form. We get thus for each
compound all theoretical isotopologues that would result in an intensity higher
than the specified threshold (0.01% of the intensity from the monoisotopic
mass). For each of these peaks we define its *isotopologue id* which
consists of the observed isotopes for that compound, e.g. `"4[13C]2[15N]"` for
isotopologues of all compounds that contain this isotope composition.

```{r, echo = FALSE}
dr <- paste0("data/RData/isotope-intensity-estimation/")
dir.create(dr, showWarnings = FALSE, recursive = TRUE)
```

<!--- This should not be needed anymore with the updated code in the next chunk
```{r, eval = FALSE}
# Cl and only Cl is not positioned in the same manner in the HMBD formulae. So
# that can originate configurations like 1[2H]1[37Cl] and 1[37Cl]1[2H]. So maybe 
# I could use this frmls2 instead of cmps$formula or fix in the code to take 
# this into account
frmls2 <- apply(counts_df, 1, function(x) paste0(sapply(seq_along(x), 
          function(i) ifelse(x[i] > 0, paste0(colnames(counts_df)[i], 
          ifelse(x[i] > 1, x[i], "")), "")), collapse = ""))
```
---->

```{r, eval = !file.exists(paste0(dr, "cnf_frequencies.RData"))}
data(isotopes)
## Ensure that element order is correct
chemforms <- sapply(cmps$formula, standardizeFormula)
threshold = 0.01
iso_ps <- isopattern(isotopes, chemforms , threshold = threshold)
# iso_ps <- isopattern(isotopes, c("Fe", "C4H3BrN2") , threshold = threshold)

## Process the isotope pattern to define a character string for each
## isotopologue - ensuring the order of isotopes to be the same across
## compounds
isos <- c("13C", "2H", "15N", "17O", "18O", "33S", "34S", "35S", "36S", 
          "36Cl", "37Cl")
cnf_per_cmpd <- lapply(iso_ps, function(iso_p) {
    idx <- match(colnames(iso_p), isos)
    tmp <- iso_p[, !is.na(idx), drop = FALSE]
    tmp <- tmp[rowSums(tmp) > 0, order(idx[!is.na(idx)]), drop = FALSE]
    cn <- colnames(tmp)
    apply(tmp, 1, function(row)
        paste0(row[row >0], "[", cn[row > 0], "]", collapse = ""))
})
cnf_frequency <- table(unlist(cnf_per_cmpd, use.names = FALSE))

save(cnf_frequency, cnf_per_cmpd, file = paste0(dr, "cnf_frequencies.RData"))
```

<!--- 
Or do the same based on the mz differences with respect to monoisotopic mass
---->

```{r, echo = FALSE, eval = file.exists(paste0(dr, "cnf_frequencies.RData"))}
load(paste0(dr, "cnf_frequencies.RData"))
```

We thus defined `r length(cnf_frequency)` isotopologues considering all
compounds from HMDB which would yield an intensity higher than 0.01% of the
monoisotopic's intensity.


```{r}
cnf_proportion <- sort(cnf_frequency / nrow(cmps), decreasing = TRUE)
par(mar = c(8, 4.1, 4.1, 2.1))
barplot(cnf_proportion[cnf_proportion > 0.5], las = 2)
```

In the plot above we can see isotopologues for compounds in HMBD that produce a
*significant* peak for at least a half of the compounds (the height of the bar
specifies the exact proportion). In other words, if we randomly sample a compund
in HMBD the chance to observe a significant peak related to the above
isotopologues will be high. I observe however that this approach penalizes
families related to elements with low counts in HMBD compounds. The number of
times a family related to N, S or Cl is found to be significant is limited by
the fact that the number of compounds in HMBD that contain these elements is
much lower than those that contain C, H, or O.

We thus next compare the isotopologue frequency not against the total number of
compounds in HMDB, but against the number of compounds in HMDB that contain each
of the elements from the isotopologue definition in their chemical formula.

```{r}
ncomps <- vapply(names(cnf_frequency), function(x) {
    x <- unlist(strsplit(x, split = "\\]"))
    x <- gsub("[0-9\\[]+", "", x)
    ## require at least one element for each element in the
    ## isotopologue definition
    sum(rowSums(counts_df[, x, drop = FALSE] > 0) == length(x))
}, integer(1))
```

```{r, fig.height = 5, fig.width = 17}
cnf_proportion_var <- sort(cnf_frequency/ncomps, decreasing = TRUE)
par(mar = c(10, 4.1, 4.1, 2.1))
barplot(cnf_proportion_var[cnf_proportion_var > 0.5], las = 2)
```


Here I also try to divide the counts of the times a family is found to be 
significant in the HMBD compounds for the times that this family can be 
observed across the HMBD compounds. In other words these ratios represent the 
likelihood to find a family significant among the subset of HMBD compounds that 
have it as possible family of configurations(this happens when, for each element 
$X$ in the compound, the number of atoms of $X$ is >= than the sum of the 
numbers ${n_X}_2$, ..., ${n_X}_q$ of heavier isotopes specified in the family of 
configurations).

```{r}
count_heavy_iso <- function(cnf_str)
{
  tmp <- strsplit(cnf_str, "]")[[1]]
  names(tmp) <- sapply(tmp, function(s) strsplit(s, "\\[")[[1]][2])
  heavy_iso <- sapply(tmp, function(s) as.numeric(strsplit(s, "\\[")[[1]][1])) 
  tapply(heavy_iso, gsub('[0-9]+', '', names(heavy_iso)), sum)
}

nvar <- sapply(names(cnf_frequency), function(cnf) {
  els <- count_heavy_iso(cnf)
  var <- rep(TRUE, nrow(counts_df))
  for (el in names(els)) 
    var <- var & (counts_df[, el] >= els[el])
  sum(var)
})
```


```{r, fig.height = 5, fig.width = 17}
cnf_proportion_var <- sort(cnf_frequency/nvar, decreasing = TRUE)[-1]
par(mar = c(10, 4.1, 4.1, 2.1))
barplot(cnf_proportion_var[cnf_proportion_var > 0.5], las = 2)
```

In the plot above we can see the families of configurations produce a significant 
peak for at least a half of the compounds in which they are possible. 
(the height of the bar specifies the exact proportion). In this case we observe 
also families where N, S or Cl in them. 
To exemplify the difference, all molecules (the proportion in the above plot is 
1) of HMBD that have at least 1 atom of C and 1 atom of Cl are found to have 
significant peaks corresponding to 1[13C]1[37Cl]. However, since the number of 
such compounds in HMBD is very low the probability of observing the effect of 
such a configuration is very very low if we randomly pick one compound in HMBD.



<!---
Finally I could also consider an approach along these lines. In the approach before 
we summed 1 to the score of the configuration if it was found significant in a compound.
Instead of summing 1 we could sum the intensity of the associated peak in the isotope
pattern. Then we could select the families that generate the most intensity across
HMBD compounds.
--->

### Discussion

- [ ] Is the updated description/definition of terms OK?
- [ ] What's the difference between the two approaches to have *relative*
      proportion of isotopologues.
- [ ] m/z dependent isotopologues: check if the m/z matches ~ the mass of the
      isotopologue definition. Considering an isotopologue 9[13C]2[18O] would
      not make sense for an m/z that is lower than the mass of this
      isotopologue.

## Isotopes related definitions

Here we define a list of overall configurations (or isotopes, if we want to use 
the previous terminology). Let $(C_X,C_Y,...,C_Z)$ be an overall configuration. 
If, for example, $C_Y$ is $(n_Y,0,...,0)$ we don't report $C_Y$ in the list 
although it should be present for completeness. 
However the code will know that if $C_Y$ is absent then it is $(n_Y,0,...,0)$.
For a given configuration of atoms of a given element, say $Y$, we report only 
the number of each heavier isotope ($2,...q$) of the element i.e. 
(${n_Y}_2$, ..., ${n_Y}_q$). ${n_Y}_1$ will be determined by the code as 
$n_Y-({n_Y}_2...+{n_Y}_q)$.

```{r}
# confs <- list(C13 = list(C = c(1)),
#               `2C13` = list(C = c(2)),
#               N15 = list(N = c(1)),
#               O17 = list(O = c(1,0)),
#               O18 = list(O = c(0, 1)),
#               S33 = list(S = c(1, 0, 0, 0)),
#               S34 = list(S = c(0, 1, 0, 0)),
#               #C13O18 = list(C = c(1), O = c(0, 1)),
#               Cl37 = list(Cl = c(1)))
```

Here I construct a list of configurations similar to the one above based on the 
configurations selected in the previous section. I convert the strings to the 
list (but we can also change this representation) as used by the functions in 
the rest of the file. 

```{r}
selected_names <- names(cnf_proportion_var[cnf_proportion_var > 0.5])
h_iso_forms <- list(C = c("13C"), H = c("2H"), N = c("15N"), O = c("17O", "18O"), 
                    S = c("33S", "34S", "36S"), Cl = c("37Cl"))

confs <- lapply(selected_names, function(name) {
  splt <- strsplit(name, "]")[[1]]
  conf_v <- sapply(splt, function(s) as.numeric(strsplit(s, "\\[")[[1]][1]))
  names(conf_v) <- sapply(splt, function(s) strsplit(s, "\\[")[[1]][2])
  elements <- gsub('[0-9]', '', names(conf_v))
  conf <- lapply(unique(elements), function(el) {
    el_conf_names <- h_iso_forms[[el]]
    el_conf <- rep(0, length(el_conf_names))
    names(el_conf) <- el_conf_names
    subs <- conf_v[elements == el]
    el_conf[names(subs)] <- subs
    el_conf
  })
  names(conf) <- unique(elements)
  conf
})
names(confs) <- selected_names
```

<!---
We next define the (**single charged**) isotopes (with the understanding that 
actually their are not isotopes in the sense of the definition but more what 
I named as configurations) which we will consider along with their natural 
occurring relative abundance.


```{r}
# I added also H2 and 3C13 just to see how they look like
isotopes <- data.frame(
    element = c("C", "C", "N", "O", "O", "S", "S", "Cl", "H", "C"),
    isotope = c("C13", "2C13", "N15", "O17", "O18", "S33", "S34", "Cl37", 
                "H2", "3C13"),
    number_neutrons = c(1, 1, 1, 1, 2, 1, 2, 1, 1, 1),
    number_isotopes = c(1, 2, 1, 1, 1, 1, 1, 1, 1, 3),
    mass_diff = c(1.00335484, 2.00670968, 0.997034965599999, 1.0042168777,
                  2.0042457777, 0.999387810000002, 1.99579614, 1.99704989, 
                  1, 3*1.00335484),
    element_abundances = I(list(c(0.9893, 0.0107), 
                                c(0.9893, 0.0107),
                                c(0.99636, 0.00364),
                                c(0.99757, 0.00038, 0.00205), 
                                c(0.99757, 0.00038, 0.00205),
                                c(0.9499, 0.0075, 0.0425), 
                                c(0.9499, 0.0075, 0.0425),
                                c(0.7576, 0.2424),
                                c(0.99988, 0.00012),
                                c(0.9893, 0.0107))),
    cnf = I(list(c(1), c(2), c(1), c(1, 0), c(0, 1), c(1,0), c(0,1), c(1), 
                 c(1), c(3)))
)
```

The table below lists the defined isotopes.

```{r, echo = FALSE, results = "asis"}
# pandoc.table(isotopes, style = "rmarkdown",
#              caption = "Isotope definitions.")
```
--->

We define the elements we consider together with the natural abundances 
of their isotopic forms. I also define mass differences of isotopes of each 
element and a simple function to get from them the md originated by a given 
configuration. 

```{r}
# Here I added H and 36S and the related information. I took the values from 
# envipat. I wonder why some values are known with more precision
elements_ab <- list(C = c(0.9893, 0.0107),
                    H = c(0.99988500, 0.00011500),
                    N = c(0.99636, 0.00364),
                    O = c(0.99757, 0.00038, 0.00205),
                    S = c(0.9499, 0.0075, 0.0425, 0.0001),
                    Cl = c(0.7576, 0.2424))

elements_md <- list(C = c(1.00335484),
                    H = c(1.006277), 
                    N = c(0.997034965599999),
                    O = c(1.0042168777, 2.0042457777),
                    S = c(0.999387810000002, 1.99579614, 3.027929),
                    Cl = c(1.99704989))

getmd <- function(conf, elements_md) 
  sum(sapply(names(conf), function(el) sum(conf[[el]] * elements_md[[el]])))

md_confs <- sapply(confs, function(conf) getmd(conf, elements_md))
```

<!---
## Computation of probabilities to observe configurations in groups of atoms of each element

Here we consider again the compounds in HMBD. We have already computed the counts 
of C, N, O, S, Cl for each of them. We compute here the probability of observing 
certain configurations of a given element. Let's consider O to exemplify this.
Suppose that the given compound has nO atoms of O. We can compute for example the 
probability of the configuration (0 atoms of O17,1 atom of O18) or more precisely
CO=(nO-1 atoms of O16, 0 atoms of O17,1 atom of O18)
This is not the probability of observing the md difference mass O18 - mass O16.
The latter is given by $P(CO)* P((nC,0))* P((nN,0))* ...P((nCl,0))$ that is the 
probability of the overall configuration ((nO-1,0,1),(nC,0),(nN,0),...(nCl,0)). 
However P(O) constitutes a upper bound of such a probability since it gets multiplied 
by numbers smaller than 1. For this reason the computation of the probabilities
of the elemental configurations can be useful to exclude certain overall 
configurations as too unlikely.

```{r}
#' Simple helper function to calculate probabilities from counts. Later it could 
# be updated using the function P implemented in the next section
prob_from_counts <- function(x, def) {
    res <- lapply(seq_len(nrow(def)), function(i) {
        niso <- sum(def$cnf[[i]])
        sapply(x[, def$element[i]], function(n)
            ifelse(n > (niso - 1),
                   dmultinom(c(n - niso, def$cnf[[i]]),
                             prob = def$element_abundances[[i]]), 0))
    })
    res <- do.call(cbind, res)
    colnames(res) <- def$isotope
    res
}

prob_df <- prob_from_counts(counts_df[, unique(isotopes$element)], isotopes)
```

```{r, fig.width = 7, fig.height = 20, fig.cap = "Distribution of probabilities for a certain isotope."}
par(mfrow = c(ncol(prob_df), 2), mar = c(2, 4, 1, 0.5))
for (name in colnames(prob_df)) {
  hist(prob_df[, name], probability = TRUE, main = name, xlab = "", breaks = 64)
  boxplot(prob_df[, name], main = name)
  #print(paste0(name," : ", quantile(v, 0.8)))
}
```

From the plots above, if we consider N15, O17, S34, Cl37, wouldn't it make sense 
to consider also H2 and 3C13 which seem to produce higher probabilities? I don't 
know if we should also consider a overall configuration like "C13H2" for example. 
A median probability bound for this would be around 0.3..*0.1.. which is around 
the same bound we have for the overall "N15", "O17", "S34". However for now I 
will leave the things as they currently are waiting for your feedback.
--->

## Define lower and upper intensity ratio between candidate isotope peaks and the monoisotopic peak

To determine isotope groups in a spectrum we loop over its peaks. We consider the 
current peak and suppose it is the monoisotopic peak of a certain compound. 
We then find peaks that have a mzd compatible with some of the possible sums 
$md = md_{C_X}+ md_{C_Y} ... +md_{C_Z}$.
We finally determine if these peaks are actually compatible with the intensity ${Ic}_0$
of the current peak (assumed to be monoisotopic peak of a certain compound) and 
if so we group them together as a isotopic group. To check such compatibility 
we can proceed as follows.
In a isotope group spectrum the intensity $I_{md}$ of the peak associated to $md$ is 
of course equal to $I_{md}/ I_0*I_0$ where $I_0$ is the intensity associated to the 
monoisotopic mass. 
Since $I_{md}/ I_0$ approximates $P(md)/ P(0)$ we can check the compatibility of the 
candidate peak intensity ${Ic}_{md}$ with ${Ic}_0$* $P(md)/ P(0)$.

We next define a lower and upper bound for the ratio $R$ between a candidate 
isotopic peak and the assumed monoisotopic peak. This will be used to decide 
weather the two can be grouped together in an isotopic group or not.

Let be $(C_X,C_Y,...C_Z)$ the overall configuration related to the mass 
difference $md$. Then
$$R_{md} = \frac{P(md)}{P(0)} = \frac{P(C_X)* P(C_Y)... * P(C_Z)}
{P((n_X,0...,0))* P((n_Y,0...,0))... *P((n_Z,0...,0))}$$.
In all the cases we consider, many simplifications occur between numerator and 
denominator terms. As a result of that $R_md$ will depend only on the elemental 
configurations different from those of the $md = 0$ configuration of the 
monoisotopic peak.

We define some helper functions to do what we just described. 
`P` computes the probability of the elemental configuration of `c(n-sum(cnf), cnf)` 
related to the corresponding isotope probabilities in `prob`. It works also if `n`
is a vector. In that case each value of `n` originates a different elemental 
configuration and the associated probabilities are returned as a vector.
`R` computes the ratio between a given overall configuration `conf` and and the overall
configuration related to the md = 0 (i.e the one related to the monoisotopic peak).
`elements_ab` is the list of abundances of the isotopes of the considered elements.
`n` is a matrix with `length(conf)` columns . Each row of n specifies the number 
of atoms of the considered elements in a given compound.

```{r}
P <- function(n, cnf, prob){
  n0 <- n - sum(cnf)
  sapply(n0, function(n0_) ifelse(n0_ >= 0, 
                                  dmultinom(c(n0_, cnf), prob = prob), 0))
}

R <- function(n, conf, elements_ab){
  if(is.vector(n)) n <- as.matrix(n)
  el_names <- names(conf)
  res <- lapply(seq_along(conf), function(i){
    conf0_el <- rep(0, length(conf[[i]]))
    P(n[, i], conf[[i]], elements_ab[[el_names[i]]])/
      P(n[, i], conf0_el, elements_ab[[el_names[i]]])
  })
  apply(do.call(rbind, res), 2, prod)
}
```

We perform the computation of $R$ for each compound in HMBD and for each of the 
considered overall configurations
```{r}
R_from_counts <- function(counts, confs, elements_ab){
  do.call(cbind, lapply(confs, function(conf) R(counts[, names(conf)], 
                                                 conf, elements_ab)))}
# I commented the computation because it's slow and not needed in the rest of 
# the document but it works
R_df <- R_from_counts(counts_df, confs, elements_ab)
```

As we saw, $R_{md}$ depends on the counts of elements in the compound. We can 
determine lower and upper bounds on those and then obtain the 
corresponding bounds on R. We consider two different approaches: one which 
considers what the count is for most elements of HMBD, the other which considers 
the counts of the elements in HMBD as dependent on the mass.


```{r, fig.width = 7, fig.height = 20, fig.cap = "R against mass for HMBD compounds."}
# par(mfrow = c(ncol(R_df), 1), mar = c(5, 4, 1, 0.5))
# for (name in colnames(R_df)) {
#   plot(cmps$exactmass, R_df[, name], xlab = "mass", ylab = "R", main = name)
# }
```

## Mass-independent bounds

For a given element $X$ we can determine two quantiles ${q_1}_X$ and ${q_2}_X$ 
such that a certain percentage (e.g 95%) of compounds in HMBD have 
${q_1}_X<n_X<{q_2}_X$ and repeat the same for all the elements. In this first 
approach we consider the obtained quantiles as the upper and lower bounds on 
counts.

```{r}
count_limits <- apply(counts_df, 2, quantile, probs = c(0.025, 0.975))
```

We next compute the corresponding bounds on $R$

```{r}
#prob_limits <- prob_from_counts(count_limits, isotopes)
R_limits <- R_from_counts(count_limits, confs, elements_ab)
```

and save them in a txt file together with the names of  the configurations and
the related mass differences.

```{r}
R_limits <- t(R_limits)
colnames(R_limits) <- c("min_ratio", "max_ratio")
isodef <- data.frame(name = names(confs), mzd = md_confs, R_limits)
isodef <- isodef[order(isodef[, "mzd"]), ]

dr_txt <- paste0("data/txt/isotope-intensity-estimation/")
dir.create(dr, showWarnings = FALSE, recursive = TRUE)
write.table(isodef, file = paste0(dr_txt, "hmdb_isotopes_constant_range.txt"),
            sep = "\t", row.names = FALSE)
```

This approach has the following limitations, mostly because it is based on all
compounds in HMDB regardless of their mass:
- the lower limit for C13 might be too large, because of the lower limit of
  carbon atom counts used (i.e. `r count_limits[1, "C"]`). The lower intensity
  threshold will be too large for all compounds with less C atoms.
- for *Cl37* both the lower and upper intensity limit is 0, thus we will never
  identify any such isotope.

TODO:

- [ ] Should we consider to lower the count for C13 (i.e. set it manually to 1)?
- [ ] For Cl37, should we increase the upper count?
- [ ] Should we use the `range` instead of the quantiles?

Comments & questions 

If I understand your question correctly using the range is equivalent to 
the extreme case of using quantiles 0 and 1. This would allow us to create bounds
that are fulfilled by all elements in HMBD. The side effect is that we would end 
up with larger intervals and as a result of that we would be less able to 
discriminate if the candidate peak is good. For example, imagine the current peak
having intensity 1000 is related to a compound with 50 atoms of carbon. In this case 
R for the C13 configuration would be 0.5407864 meaning the candidate peak should 
be around 541 in intensity. But imagine the candidate peak we are checking is 50
in intensity. If we chose to use the range or very high quantiles, the bounds would 
be so large that we would accept the 50 intensity peak even though the expected intensity
is around 541. So there is a trade off between choosing extreme quantiles (in this 
case the probability of not classifying a correct peak is very low, but it is higher the 
probability of classifying a wrong peak) and choosing less extreme ones (in this 
case the probability of not classifying a correct peak is higher, but it is lower the 
probability of classifying a wrong peak). We would have to find the right 
compromise between the two errors based maybe on which one of the two we consider 
less important.

Should we consider different quantiles for different elements? For example 
we could consider a higher upper quantile for Cl so that the upper bound is not 0.


## Define mass-dependent bounds

We next evaluate what the relationship between the compound's mass and its
number of specific atoms. We use this later to determine a mass-dependent
factor to estimate the expected intensity of a certain isotope.

We try to fit a regression line for masses of molecules versus the number of 
atoms for the elements $C, N, O, S, Cl$ in the HMBD compounds. We expect in general 
to have higher counts of the elements for a higher mass. 

```{r, fig.width = 7, fig.height = 20}
par(mfrow = c(5, 1), mar = c(3, 4, 1, 0.5))
for (el in c("C", "N" , "O", "S", "Cl")) {
counts_el <- counts_df[, el]
exactmass <- cmps$exactmass
# idx <- which(counts_df[, el] > 0 )#& exactmass<300)
# counts_el <- counts_el[idx]
# exactmass <- exactmass[idx]

lm <- lm(counts_el ~ exactmass)
plot(counts_el ~ exactmass, ylab = "counts", xlab = "exactmass", main = el)
abline(lm , col = "red")
}
```
The regression doesn't appear to work very well apart from $C$ and maybe $O$. We 
try to construct two lines representing mass dependent lower and upper bounds for 
the counts. First, for each element, we compute the slope of the line through the 
origin and each (count, mass) point.

```{r}
slp <- counts_df/cmps$exactmass
q_slp <- apply(slp, 2, function(x) quantile(x, c(0.01, 0.999))) # values to be chosen
```

Then we fit a regression to the points with top and low (?%) of the value of the 
slope (actually, in principle we could directly use the value of the quantile as 
a value of the slope of the lower/upper bound line). We plot the results, 
store the values of the slopes.

```{r, fig.width = 7, fig.height = 20}
#I’ m not sure if maybe it would be best to fit a regression line through the 
# origin (i.e removing the intercept from the lm estimation). 
slp_bounds <- list()
par(mfrow = c(5, 1), mar = c(3, 4, 1, 0.5))
for (el in c("C", "H", "N" , "O", "S", "Cl")) {
high <- which(slp[, el] > q_slp[2, el])
low <- which(slp[, el] <= q_slp[1, el])
plot(cmps$exactmass, counts_df[, el], ylab = "counts", xlab = "exactmass", 
     main = el)
points(cmps$exactmass[low], counts_df[low, el], col = "green")
points(cmps$exactmass[high], counts_df[high, el], col = "blue")
lm_l <- lm(counts_df[low, el] ~ cmps$exactmass[low] -1)
lm <- lm(counts_df[, el] ~ cmps$exactmass -1)
lm_h <- lm(counts_df[high, el] ~ cmps$exactmass[high] -1 )
abline(lm_l, col)
abline(lm, col = "red")
abline(lm_h)

slp_bounds[[el]] <- c(low = unname(lm_l$coefficients), 
                        high = unname(lm_h$coefficients))
}
```

and save them to a txt file.

```{r}
slp_bounds <- data.frame(slp_bounds)
```

<!---
TODO

- [ ] decide how to define the lower and upper bound. Should we exclude count of
      0 (since if we look for an isotope of a certain element we (should) expect
      that the compound contains at least one atom - otherwise we would anyway
      not detect/find the isotope)?
- [ ] define intercept and slope for lower and upper bound (number of atoms
      depending on mass).
- [ ] isotope detection function: have a function that takes that and, given a
      mass (or m/z) calculates the lower and upper count of atoms and from that
      calculates the probability. The *isotope definition* `data.frame` should
      contain all the required information to perform that calculation and
      should be passed along to this function.
--->

Here we try to exclude the points with count = 0. This can be justified by the
following fact. Suppose that in a spectrum the mass difference between a peak 
and the assumed monoisotopic peak is matched to a certain $md$. We know 
that $md$ is associated to a certain family of configurations and therefore to a
certain number of heavier isotopic forms of certain elements. It follows that if 
the candidate peak is from the isotopic pattern it must have at least a number of 
each element equal to the sum of the numbers of heavier isotopic form in the 
configuration.

```{r}
# Based on the plots, we could decide to use different quantiles for each element
pq <- data.frame(C = c(0.01, 0.99),
                 H = c(0.01, 0.99),
                 N = c(0.01, 0.99),
                 O = c(0.01, 0.99),
                 P = c(0.01, 0.99),
                 S = c(0.01, 0.99),
                 Cl = c(0.01, 0.99))
pos_idxs <- apply(counts_df, 2, function(col) unname(which(col > 0)))
q_slp2 <- lapply(names(pos_idxs), function(el) quantile(slp[pos_idxs[[el]], el], 
                                                        pq[, el]))
q_slp2 <- do.call(cbind, q_slp2)
colnames(q_slp2) <- names(pos_idxs)
```

Then we fit a regression to the points with top and low (?%) of the value of the 
slope.

```{r, fig.width = 7, fig.height = 20}
#I’ m not sure if maybe it would be best to fit a regression line through the 
# origin (i.e removing the intercept from the lm estimation). 
slp_bounds2 <- list()
par(mfrow = c(6, 1), mar = c(3, 4, 1, 0.5))
for (el in c("C", "H", "N" , "O", "S", "Cl")) {
high <- intersect(which(slp[, el] > q_slp2[2, el]), pos_idxs[[el]])
low <- intersect(which(slp[, el] <= q_slp2[1, el]), pos_idxs[[el]])
plot(cmps$exactmass[pos_idxs[[el]]], counts_df[pos_idxs[[el]], el], 
     ylab = "counts", xlab = "exactmass", main = el, 
     ylim = c(0, max(counts_df[pos_idxs[[el]], el])))
points(cmps$exactmass[low], counts_df[low, el], col = "green")
points(cmps$exactmass[high], counts_df[high, el], col = "blue")
lm_l <- lm(counts_df[low, el] ~ cmps$exactmass[low] -1)
#lm <- lm(counts_df[pos_idxs[[el]], el] ~ cmps$exactmass[pos_idxs[[el]]] -1)
lm_h <- lm(counts_df[high, el] ~ cmps$exactmass[high] -1 )
abline(lm_l, col)
#abline(lm, col = "red")
abline(lm_h)

slp_bounds2[[el]] <- c(low = unname(lm_l$coefficients), 
                        high = unname(lm_h$coefficients))
}
```

Here is a first tentative function to get the bounds on R for a specific mass
```{r}
get_R_bound <- function(mass, slp_bounds){
  count_bounds <-  slp_bounds*mass 
  R_from_counts(count_bounds, confs, elements_ab)
}
```

```{r}
slope_bounds <- do.call(rbind, slp_bounds2)
write.table(slope_bounds, file = paste0(dr_txt, "slope_bounds.txt"),
            sep = "\t", row.names = TRUE)
```

# Session information

The R version and packages used in this analysis are listed below.

```{r sessioninfo}
sessionInfo()
```
